{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bd3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from model_classes_ import GCN_classification, GCN_regression, MLP_Classification, MLP_Regression#, SimpleCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0868b2-66bf-455f-8380-9eb42b18517b",
   "metadata": {},
   "source": [
    "# Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21fc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name='GCN'):\n",
    "    '''\n",
    "    Trains model for classification task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch\n",
    "    train_AUROC_vec [array]: Training AUROC score for each epoch\n",
    "    valid_loss_vec [array]: Validation loss for each epoch\n",
    "    valid_AUROC_vec [array]: Validation AUROC score for each epoch\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()        \n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores) \n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = to_cpu_npy(train_softmax)\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = to_cpu_npy(valid_softmax)\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:,1], average=\"micro\")\n",
    "        \n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec\n",
    "\n",
    "\n",
    "def train_model_regression(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name='GCN'):\n",
    "    '''\n",
    "    Trains model for regression task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch;\n",
    "        analagous for valid_loss_vec (validation set)\n",
    "    train_pearson_vec [array]: Training PCC for each epoch;\n",
    "        analogous for valid_pearson_vec (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()\n",
    "        \n",
    "        \n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.FloatTensor(train_labels).to(device))\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        train_scores = to_cpu_npy(train_scores)\n",
    "        train_pearson = calc_pearson(train_scores, train_labels)\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.FloatTensor(valid_labels).to(device))\n",
    "        valid_scores = to_cpu_npy(valid_scores)\n",
    "        valid_pearson  = calc_pearson(valid_scores, valid_labels)\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        \n",
    "        train_pearson_vec[e] = train_pearson\n",
    "        valid_pearson_vec[e] = valid_pearson\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32296307-19f7-46bd-8947-720bc505e63b",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d3b1f8-3b8a-4316-8e55-4b1bcc8a3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx, name='GCN'):\n",
    "    '''\n",
    "    Runs fully trained classification model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_AUROC [float]: Test set AUROC score;\n",
    "        analogous for train_AUROC (training set) and valid_AUPR (validation set)\n",
    "    test_AUPR [float]: Test set AUPR score\n",
    "        analogous for train_AUPR (training set) and valid_AUPR (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels;\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    if name == 'GCN':\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "    elif name == 'MLP':\n",
    "        forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "    \n",
    "    test_scores = forward_scores[test_idx]\n",
    "    \n",
    "    test_softmax, test_pred = model.calc_softmax_pred(test_scores) \n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_pred = to_cpu_npy(test_pred)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_precision, test_recall, thresholds = precision_recall_curve(test_labels, test_softmax[:,1])\n",
    "    test_AUPR = auc(test_recall, test_precision)\n",
    "    # test_F1 = f1_score(test_labels, test_pred, average=\"micro\")\n",
    "    \n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_softmax, train_pred = model.calc_softmax_pred(train_scores) \n",
    "    train_pred = to_cpu_npy(train_pred)\n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_precision, train_recall, thresholds = precision_recall_curve(train_labels, train_softmax[:,1])\n",
    "    train_AUPR = auc(train_recall, train_precision)\n",
    "    # train_F1 = f1_score(train_labels, train_pred, average=\"micro\")\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_softmax, valid_pred = model.calc_softmax_pred(valid_scores) \n",
    "    valid_pred = to_cpu_npy(valid_pred)\n",
    "    valid_softmax = to_cpu_npy(valid_softmax)\n",
    "    valid_precision, valid_recall, thresholds = precision_recall_curve(valid_labels, valid_softmax[:,1])\n",
    "    valid_AUPR = auc(valid_recall, valid_precision)\n",
    "    # valid_F1 = f1_score(valid_labels, valid_pred, average=\"micro\")\n",
    "\n",
    "    return test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels\n",
    "\n",
    "\n",
    "def eval_model_regression(model, graph, targetNode_mask, train_idx, valid_idx, test_idx, name='GCN'):\n",
    "    '''\n",
    "    Runs fully trained regression model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_pearson [float]: PCC for test set;\n",
    "        analogous for train_pearson (training set) and valid_pearson (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels (expression values);\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    if name == 'GCN':\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "    elif name == 'MLP':\n",
    "        forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_pred = to_cpu_npy(test_scores)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    test_pearson = calc_pearson(test_pred, test_labels)\n",
    "\n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_pred = to_cpu_npy(train_scores)\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_pearson = calc_pearson(train_pred, train_labels)\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_pred = to_cpu_npy(valid_scores)\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_pearson = calc_pearson(valid_pred, valid_labels)\n",
    "\n",
    "    return test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96a190-83cf-4bb4-8f04-61933b4c3214",
   "metadata": {},
   "source": [
    "# Pearson score calculator + GPU to CPU tensor Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dc3213-0461-4837-a8af-33e325009273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pearson(scores, targets):\n",
    "    '''\n",
    "    Calculates Pearson correlation coefficient (PCC) between predicted \\\n",
    "        expression levels and true expression levels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores [array]: Predicted expression levels\n",
    "    targets [array]: True expression levels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pcc [float]: Pearson correlation coefficient\n",
    "\n",
    "    '''\n",
    "    scores = scores.squeeze()\n",
    "    targets = targets.squeeze()\n",
    "    pcc, _ = pearsonr(scores, targets)\n",
    "            \n",
    "    return pcc\n",
    "    \n",
    "    \n",
    "def to_cpu_npy(x):\n",
    "    '''\n",
    "    Simple helper function to transfer GPU tensors to CPU numpy matrices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x [tensor]: PyTorch tensor stored on GPU\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_x [array]: Numpy array stored on CPU\n",
    "\n",
    "    '''\n",
    "\n",
    "    new_x = x.cpu().detach().numpy()\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70354865",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc67fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains and evaluates models\n",
    "###Test for GPU availability\n",
    "cuda_flag = torch.cuda.is_available()\n",
    "if cuda_flag:  \n",
    "  dev = \"cuda\" \n",
    "else:\n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6bda395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(cell_line, regression_flag, model, max_epoch=50, learning_rate=0.001, name='GCN'):\n",
    "    \"\"\"\n",
    "    \n",
    "        Trains and evaluates models.\n",
    "        \n",
    "        Parameters:\n",
    "        cell_line: cell line to be trained on\n",
    "        regression_flag: 0 (Classification) or 1 (Regression)\n",
    "        model: GCN, MLP, or CNN model\n",
    "        name: GCN, MLP, CNN\n",
    "        \n",
    "        Returns:\n",
    "        Performance scores based on type of task\n",
    "        \n",
    "    \"\"\"\n",
    "    if regression_flag == 0:\n",
    "        num_classes = 2\n",
    "        task = 'Classification'\n",
    "    else:\n",
    "        num_classes = 1\n",
    "        task = 'Regression'\n",
    "\n",
    "    # random_seed = random.randint(0,10000)\n",
    "    # random.seed(random_seed)\n",
    "    # np.random.seed(random_seed)\n",
    "    # torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "    ###Initialize start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    today = date.today()\n",
    "    mdy = today.strftime(\"%Y-%m-%d\")\n",
    "    clock = datetime.now()\n",
    "    hms = clock.strftime(\"%H-%M-%S\")\n",
    "    hm = clock.strftime(\"%Hh-%Mm\")\n",
    "    hm_colon = clock.strftime(\"%H:%M\")\n",
    "    date_and_time = mdy + '-at-' + hms\n",
    "    \n",
    "    ###Load input files\n",
    "    base_path = os.getcwd()\n",
    "    save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "    df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "    # Load data\n",
    "    mat = load_npz(hic_sparse_mat_file)\n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "    hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "    allNodes = allNodes_hms[:, 0].astype(int)\n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    if regression_flag == 0:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).long()\n",
    "    else:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).float()\n",
    "\n",
    "    extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "    data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "    G = data\n",
    "    \n",
    "    # Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "    pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "    fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "    fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "    train_idx = pred_idx_shuff[:fin_train]\n",
    "    valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "    test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "    train_gene_ID = targetNode_mask[train_idx].numpy()\n",
    "    valid_gene_ID = targetNode_mask[valid_idx].numpy()\n",
    "    test_gene_ID = targetNode_mask[test_idx].numpy()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    # print(\"\\n\"+\"Model's state_dict:\")\n",
    "    # for param_tensor in model.state_dict():\n",
    "    #     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "    ### For classification:\n",
    "    if regression_flag == 0:\n",
    "\n",
    "        ### Train model\n",
    "        train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "            train_model_classification(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name=name)\n",
    "\n",
    "        ### Evaluate model\n",
    "        test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "                valid_AUPR, valid_pred, valid_labels = \\\n",
    "                    eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx, name=name)\n",
    "\n",
    "        ### Save metrics and node predictions\n",
    "        train_metrics = [train_gene_ID, train_pred, train_labels, train_AUROC_vec, train_AUPR, train_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), train_metrics)\n",
    "\n",
    "        valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_AUROC_vec, valid_AUPR, valid_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), valid_metrics)\n",
    "\n",
    "        test_metrics = [test_gene_ID, test_pred, test_labels, test_AUROC, test_AUPR, ['na']]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), test_metrics)\n",
    "\n",
    "        dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "        df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label','Classification'])\n",
    "\n",
    "        for d in np.arange(len(dataset_list)):\n",
    "            dataset_metrics = dataset_list[d]\n",
    "            partial_metrics = pd.DataFrame()\n",
    "\n",
    "            partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "            partial_metrics['True Label'] = dataset_metrics[2]\n",
    "            partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "            partial_metrics['Classification'] = dataset_metrics[1]*1 + dataset_metrics[2]*2\n",
    "            partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=1, value='FP', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=2, value='FN', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=3, value='TP', inplace=True)\n",
    "\n",
    "            if d == 0:\n",
    "                partial_metrics['Dataset'] = 'Training'\n",
    "            elif d == 1:\n",
    "                partial_metrics['Dataset'] = 'Validation'\n",
    "            elif d == 2:\n",
    "                partial_metrics['Dataset'] = 'Testing'\n",
    "\n",
    "            df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "\n",
    "        df_gene_names = df_genes.iloc[:,:3]\n",
    "        df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                      \"hic_node_id\" : 'Node ID'})\n",
    "        df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "        df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,5,6,2,3,4]]]\n",
    "\n",
    "    ### For regression:\n",
    "    elif regression_flag == 1:\n",
    "\n",
    "        ### Train model\n",
    "        train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "            train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name=name)\n",
    "\n",
    "        ### Evaluate model\n",
    "        test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "                valid_pearson, valid_pred, valid_labels = \\\n",
    "                    eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx, name=name)\n",
    "\n",
    "        ### Save metrics and node predictions\n",
    "        train_metrics = [train_gene_ID, train_pred, train_labels, train_pearson_vec, train_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), train_metrics)\n",
    "\n",
    "        valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_pearson_vec, valid_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), valid_metrics)\n",
    "\n",
    "        test_metrics = [test_gene_ID, test_pred, test_labels, test_pearson, ['na']]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), test_metrics)\n",
    "\n",
    "        dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "        df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label'])\n",
    "\n",
    "        for d in np.arange(len(dataset_list)):\n",
    "            dataset_metrics = dataset_list[d]\n",
    "            partial_metrics = pd.DataFrame()\n",
    "\n",
    "            partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "            partial_metrics['True Label'] = dataset_metrics[2]\n",
    "            partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "\n",
    "            if d == 0:\n",
    "                partial_metrics['Dataset'] = 'Training'\n",
    "            elif d == 1:\n",
    "                partial_metrics['Dataset'] = 'Validation'\n",
    "            elif d == 2:\n",
    "                partial_metrics['Dataset'] = 'Testing'\n",
    "\n",
    "            df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "\n",
    "        df_gene_names = df_genes.iloc[:,:3]\n",
    "        df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                      \"hic_node_id\" : 'Node ID'})\n",
    "        df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "        df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,4,5,2,3]]]\n",
    "\n",
    "\n",
    "    ### Print elapsed time and performance\n",
    "    elapsed = (time.time() - start_time)\n",
    "    elapsed_h = int(elapsed//3600)\n",
    "    elapsed_m = int((elapsed - elapsed_h*3600)//60)\n",
    "    elapsed_s = int(elapsed - elapsed_h*3600 - elapsed_m*60)\n",
    "    print('Elapsed time: {0:02d}:{1:02d}:{2:02d}'.format(elapsed_h, elapsed_m, elapsed_s))\n",
    "\n",
    "    \n",
    "    print('Performance:')\n",
    "    if regression_flag == 0:\n",
    "        print('Test AUROC:', test_AUROC, '\\n')\n",
    "        return test_AUROC\n",
    "    \n",
    "    elif regression_flag == 1:\n",
    "        print('Test pearson:', test_pearson, '\\n')\n",
    "        return test_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30edcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores AUROC, AUPR, and PCC across all models for each cell line\n",
    "data_dict = {}\n",
    "data_dict['E116'] = {'AUROC': [None, None, None], 'PCC': [None, None, None]}\n",
    "data_dict['E122'] = {'AUROC': [None, None, None], 'PCC': [None, None, None]}\n",
    "data_dict['E123'] = {'AUROC': [None, None, None], 'PCC': [None, None, None]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b91ba7",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b23c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set random seed\n",
    "# random_seed = random.randint(0,10000)\n",
    "# random.seed(random_seed)\n",
    "# np.random.seed(random_seed)\n",
    "# torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2816c72e-ef9c-4557-8a2c-2e609ba53b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "regression_flag = 0\n",
    "max_epoch = 50\n",
    "learning_rate = 0.001\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 100\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_runs = 10\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "lin_hidden_sizes_r = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, 1)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [1]\n",
    "lin_hidden_sizes_c = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, 2)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e13c30-ace4-46c6-8014-1f313afae8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_n(cell_line, num_runs, model_c, model_r, name, max_epoch=50, models={'MLP': 0, 'GCN': 1, 'CNN': 2}):\n",
    "    \"\"\"\n",
    "        Trains and evaluates the models over a certain number of runs.\n",
    "        This function calculates average and standard deviation values\n",
    "        and populates fields in the data_dict dictionary according for\n",
    "        each model.\n",
    "\n",
    "        Parameters:\n",
    "            num_runs: number of times to execute the experiment\n",
    "            model_c: classification model\n",
    "            model_r: regression model\n",
    "            name: MLP, GCN, or CNN\n",
    "            models: maps index to position in data_dict\n",
    "            \n",
    "    \"\"\"\n",
    "    aurocs = []\n",
    "    pccs = []\n",
    "\n",
    "    print('Classification Task...')\n",
    "    for i in range(num_runs):\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        # MLP Classification Task\n",
    "        auroc = experiment(cell_line=cell_line, regression_flag=0, max_epoch=max_epoch, learning_rate=learning_rate, model=model_c, name=name)\n",
    "        aurocs.append(auroc)\n",
    "\n",
    "    print('Regression Task...')\n",
    "    for i in range(num_runs):\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        # MLP Regression Task\n",
    "        pearson = experiment(cell_line=cell_line, regression_flag=1, max_epoch=max_epoch+25, learning_rate=learning_rate, model=model_r, name=name)\n",
    "        pccs.append(pearson)\n",
    "\n",
    "    aurocs, pccs = np.array(aurocs), np.array(pccs)\n",
    "    data_dict[cell_line]['AUROC'][models[name]] = (np.mean(aurocs), np.std(aurocs))\n",
    "    data_dict[cell_line]['PCC'][models[name]] = (np.mean(pccs), np.std(pccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e815f84-abed-4173-bd59-7cda4b3a4c3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line: E116\n",
      "Classification Task...\n",
      "Iteration 1:\n",
      "\n",
      "\n",
      "Epoch 0 out of 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell_line \u001b[38;5;129;01min\u001b[39;00m data_dict:\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell line: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_line\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mexperiment_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcell_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mMLP_Classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin_hidden_sizes_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mMLP_Regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin_hidden_sizes_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epoch\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36mexperiment_n\u001b[0;34m(cell_line, num_runs, model_c, model_r, name, max_epoch, models)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# MLP Classification Task\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     auroc \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_line\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregression_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     aurocs\u001b[38;5;241m.\u001b[39mappend(auroc)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegression Task...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 100\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(cell_line, regression_flag, model, max_epoch, learning_rate, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# print(\"\\n\"+\"Model's state_dict:\")\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# for param_tensor in model.state_dict():\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m### For classification:\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regression_flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m### Train model\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 100\u001b[0m         \u001b[43mtrain_model_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetNode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m### Evaluate model\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n\u001b[1;32m    104\u001b[0m             valid_AUPR, valid_pred, valid_labels \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    105\u001b[0m                 eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx, name\u001b[38;5;241m=\u001b[39mname)\n",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m, in \u001b[0;36mtrain_model_classification\u001b[0;34m(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m train_loss  \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss(train_scores, torch\u001b[38;5;241m.\u001b[39mLongTensor(train_labels)\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     64\u001b[0m train_softmax, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcalc_softmax_pred(train_scores)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m### Calculate training and validation loss, AUROC scores\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cell_line in data_dict:\n",
    "        print(f\"Cell line: {cell_line}\")\n",
    "        experiment_n(\n",
    "            cell_line, \n",
    "            num_runs, \n",
    "            MLP_Classification(num_feat, lin_hidden_sizes_c, 2),\n",
    "            MLP_Regression(num_feat, lin_hidden_sizes_r, 1),\n",
    "            'MLP', \n",
    "            max_epoch=max_epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bfeb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd5688",
   "metadata": {},
   "source": [
    "## GC-Merge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f44a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cell_line in data_dict:\n",
    "        print(f\"Cell line: {cell_line}\")\n",
    "        experiment_n(\n",
    "            cell_line, \n",
    "            num_runs, \n",
    "            GCN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes_c, 2),\n",
    "            GCN_regression(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes_r, 1),\n",
    "            'GCN', \n",
    "            max_epoch=max_epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3f9fe",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f1183-fa26-4ebe-9574-61067523faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "regression_flag = 0\n",
    "max_epoch = 50\n",
    "learning_rate = 0.001\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 100\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_runs = 10\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "lin_hidden_sizes_r = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, 1)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [1]\n",
    "lin_hidden_sizes_c = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, 2)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a847023-c69e-4481-b05f-720f35b386cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        INPUT_LENGTH = 6   # Length of each input sequence (sequence_length)\n",
    "        NUM_CLASSES = 2    # Binary classification\n",
    "\n",
    "        # Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * INPUT_LENGTH, 32)\n",
    "        self.fc2 = nn.Linear(32, NUM_CLASSES)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "    \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all paths\n",
    "regression_flag = 0\n",
    "cell_line = 'E116'\n",
    "base_path = os.getcwd()\n",
    "hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "    'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "    'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357747ce-c391-4822-b1e5-f93645b5b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = load_npz(hic_sparse_mat_file)\n",
    "allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "hms = allNodes_hms[:, 1:] # only includes features, not node ids\n",
    "X = torch.tensor(hms).float().reshape(-1, num_feat) # shape: [279606, 6]\n",
    "allNodes = allNodes_hms[:, 0].astype(int) # shape: [279606,1]\n",
    "\n",
    "geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "geneNodes = geneNodes_labs[:, -2].astype(int) # shape: [16699,1]\n",
    "allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "targetNode_mask = torch.tensor(geneNodes).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886b022-0eaa-44c6-a5e0-bdc0ac3c69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate y labels\n",
    "geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "allLabs[geneNodes] = geneLabs\n",
    "Y = torch.tensor(allLabs).long() # shape: [279606,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f12c29-5cc8-4ceb-aec4-8d85c5d7ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle indices\n",
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "val_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94790a-f7f5-4858-8af1-57ab17cedc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train, validation, and test sets\n",
    "train_data = X[targetNode_mask][train_idx]\n",
    "train_labels = torch.tensor(geneNodes_labs[train_idx][:,1]).long()\n",
    "\n",
    "val_data = X[targetNode_mask][val_idx]\n",
    "val_labels = torch.tensor(geneNodes_labs[val_idx][:,1]).long()\n",
    "\n",
    "test_data = X[targetNode_mask][test_idx]\n",
    "test_labels = torch.tensor(geneNodes_labs[test_idx][:,1]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71ac02-bf25-481d-9c71-7f47dcf90a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.unsqueeze(1)\n",
    "val_data = val_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bfe39-6021-46e1-acbc-ee7997fc26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_data, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabfaf3b-6881-48b9-8abe-cf0f5d694385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification_CNN(model, train_labels, valid_labels, max_epoch=10, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    '''\n",
    "    Trains model for classification task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch\n",
    "    train_AUROC_vec [array]: Training AUROC score for each epoch\n",
    "    valid_loss_vec [array]: Validation loss for each epoch\n",
    "    valid_AUROC_vec [array]: Validation AUROC score for each epoch\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()        \n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores) \n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = to_cpu_npy(train_softmax)\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = to_cpu_npy(valid_softmax)\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:,1], average=\"micro\")\n",
    "        \n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec\n",
    "\n",
    "\n",
    "def train_model_regression(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name='GCN'):\n",
    "    '''\n",
    "    Trains model for regression task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch;\n",
    "        analagous for valid_loss_vec (validation set)\n",
    "    train_pearson_vec [array]: Training PCC for each epoch;\n",
    "        analogous for valid_pearson_vec (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()\n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.FloatTensor(train_labels).to(device))\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        train_scores = to_cpu_npy(train_scores)\n",
    "        train_pearson = calc_pearson(train_scores, train_labels)\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.FloatTensor(valid_labels).to(device))\n",
    "        valid_scores = to_cpu_npy(valid_scores)\n",
    "        valid_pearson  = calc_pearson(valid_scores, valid_labels)\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        \n",
    "        train_pearson_vec[e] = train_pearson\n",
    "        valid_pearson_vec[e] = valid_pearson\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d7124-b876-4bfc-8989-023086e45db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    for batch_inputs, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch_inputs)\n",
    "        loss = criterion(output, batch_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    end = time.time()\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f'Time elapsed: {end-start} seconds')\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89142988",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e918e9c-c077-49a8-ace9-c1850083b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract the cell lines and their corresponding data\n",
    "cell_line_data = \n",
    "\n",
    "# # AUROC graphs\n",
    "# X_axis = np.arange(0,len(categories))\n",
    "# plt.bar(X_axis + 0.2, AUROC_MLP, 0.4, label='MLP')\n",
    "# plt.bar(X_axis-0.2, AUROC_GCN, 0.4, label='GCN')\n",
    "# plt.xticks(X_axis, categories)\n",
    "# plt.xlabel(\"Cell lines\")\n",
    "# plt.ylabel(\"AUROC\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # PCC Graphs\n",
    "# plt.bar(X_axis + 0.2, PCC_MLP, 0.4, label='MLP')\n",
    "# plt.bar(X_axis-0.2, PCC_GCN, 0.4, label='GCN')\n",
    "# plt.xticks(X_axis, categories)\n",
    "# plt.xlabel(\"Cell lines\")\n",
    "# plt.ylabel(\"PCC\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121179d2-6202-4fa3-ba15-fec13602bee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
