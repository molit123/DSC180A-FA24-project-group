{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bd3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from model_classes_ import GCN_classification, GCN_regression, MLP_Classification, MLP_Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21fc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name='GCN'):\n",
    "    '''\n",
    "    Trains model for classification task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch\n",
    "    train_AUROC_vec [array]: Training AUROC score for each epoch\n",
    "    valid_loss_vec [array]: Validation loss for each epoch\n",
    "    valid_AUROC_vec [array]: Validation AUROC score for each epoch\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()        \n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores) \n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = to_cpu_npy(train_softmax)\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = to_cpu_npy(valid_softmax)\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:,1], average=\"micro\")\n",
    "        \n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec\n",
    "\n",
    "\n",
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx, name='GCN'):\n",
    "    '''\n",
    "    Runs fully trained classification model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_AUROC [float]: Test set AUROC score;\n",
    "        analogous for train_AUROC (training set) and valid_AUPR (validation set)\n",
    "    test_AUPR [float]: Test set AUPR score\n",
    "        analogous for train_AUPR (training set) and valid_AUPR (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels;\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    if name == 'GCN':\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "    elif name == 'MLP':\n",
    "        forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "    \n",
    "    test_scores = forward_scores[test_idx]\n",
    "    \n",
    "    test_softmax, test_pred = model.calc_softmax_pred(test_scores) \n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_pred = to_cpu_npy(test_pred)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_precision, test_recall, thresholds = precision_recall_curve(test_labels, test_softmax[:,1])\n",
    "    test_AUPR = auc(test_recall, test_precision)\n",
    "    # test_F1 = f1_score(test_labels, test_pred, average=\"micro\")\n",
    "    \n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_softmax, train_pred = model.calc_softmax_pred(train_scores) \n",
    "    train_pred = to_cpu_npy(train_pred)\n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_precision, train_recall, thresholds = precision_recall_curve(train_labels, train_softmax[:,1])\n",
    "    train_AUPR = auc(train_recall, train_precision)\n",
    "    # train_F1 = f1_score(train_labels, train_pred, average=\"micro\")\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_softmax, valid_pred = model.calc_softmax_pred(valid_scores) \n",
    "    valid_pred = to_cpu_npy(valid_pred)\n",
    "    valid_softmax = to_cpu_npy(valid_softmax)\n",
    "    valid_precision, valid_recall, thresholds = precision_recall_curve(valid_labels, valid_softmax[:,1])\n",
    "    valid_AUPR = auc(valid_recall, valid_precision)\n",
    "    # valid_F1 = f1_score(valid_labels, valid_pred, average=\"micro\")\n",
    "\n",
    "    return test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels\n",
    "\n",
    "\n",
    "def train_model_regression(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name='GCN'):\n",
    "    '''\n",
    "    Trains model for regression task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch;\n",
    "        analagous for valid_loss_vec (validation set)\n",
    "    train_pearson_vec [array]: Training PCC for each epoch;\n",
    "        analogous for valid_pearson_vec (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()\n",
    "        \n",
    "        \n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.FloatTensor(train_labels).to(device))\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        train_scores = to_cpu_npy(train_scores)\n",
    "        train_pearson = calc_pearson(train_scores, train_labels)\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.FloatTensor(valid_labels).to(device))\n",
    "        valid_scores = to_cpu_npy(valid_scores)\n",
    "        valid_pearson  = calc_pearson(valid_scores, valid_labels)\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        \n",
    "        train_pearson_vec[e] = train_pearson\n",
    "        valid_pearson_vec[e] = valid_pearson\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec\n",
    "\n",
    "\n",
    "def eval_model_regression(model, graph, targetNode_mask, train_idx, valid_idx, test_idx, name='GCN'):\n",
    "    '''\n",
    "    Runs fully trained regression model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_pearson [float]: PCC for test set;\n",
    "        analogous for train_pearson (training set) and valid_pearson (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels (expression values);\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    if name == 'GCN':\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "    elif name == 'MLP':\n",
    "        forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_pred = to_cpu_npy(test_scores)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    test_pearson = calc_pearson(test_pred, test_labels)\n",
    "\n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_pred = to_cpu_npy(train_scores)\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_pearson = calc_pearson(train_pred, train_labels)\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_pred = to_cpu_npy(valid_scores)\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_pearson = calc_pearson(valid_pred, valid_labels)\n",
    "\n",
    "    return test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels\n",
    "        \n",
    "\n",
    "def calc_pearson(scores, targets):\n",
    "    '''\n",
    "    Calculates Pearson correlation coefficient (PCC) between predicted \\\n",
    "        expression levels and true expression levels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores [array]: Predicted expression levels\n",
    "    targets [array]: True expression levels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pcc [float]: Pearson correlation coefficient\n",
    "\n",
    "    '''\n",
    "    scores = scores.squeeze()\n",
    "    targets = targets.squeeze()\n",
    "    pcc, _ = pearsonr(scores, targets)\n",
    "            \n",
    "    return pcc\n",
    "    \n",
    "    \n",
    "def to_cpu_npy(x):\n",
    "    '''\n",
    "    Simple helper function to transfer GPU tensors to CPU numpy matrices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x [tensor]: PyTorch tensor stored on GPU\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_x [array]: Numpy array stored on CPU\n",
    "\n",
    "    '''\n",
    "\n",
    "    new_x = x.cpu().detach().numpy()\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70354865",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc67fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains and evaluates models\n",
    "###Test for GPU availability\n",
    "cuda_flag = torch.cuda.is_available()\n",
    "if cuda_flag:  \n",
    "  dev = \"cuda\" \n",
    "else:\n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6bda395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(cell_line, regression_flag, model, max_epoch=200, learning_rate=0.001, name='GCN'):\n",
    "    \"\"\"\n",
    "    \n",
    "        Trains and evaluates models.\n",
    "        \n",
    "        Parameters:\n",
    "        cell_line: cell line to be trained on\n",
    "        regression_flag: 0 (Classification) or 1 (Regression)\n",
    "        model: GCN, MLP, or CNN model\n",
    "        name: GCN, MLP, CNN\n",
    "        \n",
    "        Returns:\n",
    "        Performance scores based on type of task\n",
    "        \n",
    "    \"\"\"\n",
    "    if regression_flag == 0:\n",
    "        num_classes = 2\n",
    "        task = 'Classification'\n",
    "    else:\n",
    "        num_classes = 1\n",
    "        task = 'Regression'\n",
    "\n",
    "    # random_seed = random.randint(0,10000)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "    ###Initialize start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    today = date.today()\n",
    "    mdy = today.strftime(\"%Y-%m-%d\")\n",
    "    clock = datetime.now()\n",
    "    hms = clock.strftime(\"%H-%M-%S\")\n",
    "    hm = clock.strftime(\"%Hh-%Mm\")\n",
    "    hm_colon = clock.strftime(\"%H:%M\")\n",
    "    date_and_time = mdy + '-at-' + hms\n",
    "    \n",
    "    ###Load input files\n",
    "    base_path = os.getcwd()\n",
    "    save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "    df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "    # Provide hyperparameters\n",
    "#     print(os.path.basename(__file__))\n",
    "    print('Model date and time:')\n",
    "    print(date_and_time, '\\n\\n')\n",
    "    print('Cell line:', cell_line)\n",
    "    print('Task:', task)\n",
    "    print('ChIP-seq resolution:', str(chip_res))\n",
    "    print('\\n')\n",
    "    print('Training set: 70%')\n",
    "    print('Validation set: 15%')\n",
    "    print('Testing set: 15%')\n",
    "    print('\\n')\n",
    "    print('Model hyperparameters: ')\n",
    "    print('Number of epochs:', max_epoch)\n",
    "    print('Learning rate:', learning_rate)\n",
    "    \n",
    "    # Load data\n",
    "    mat = load_npz(hic_sparse_mat_file)\n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "    hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "    allNodes = allNodes_hms[:, 0].astype(int)\n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    if regression_flag == 0:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).long()\n",
    "    else:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).float()\n",
    "\n",
    "    extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "    data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "    G = data\n",
    "    \n",
    "    # Define convolutional and linear layer input/output sizes\n",
    "    graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "    lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, num_classes)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "    \n",
    "    # Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "    pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "    fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "    fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "    train_idx = pred_idx_shuff[:fin_train]\n",
    "    valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "    test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "    train_gene_ID = targetNode_mask[train_idx].numpy()\n",
    "    valid_gene_ID = targetNode_mask[valid_idx].numpy()\n",
    "    test_gene_ID = targetNode_mask[test_idx].numpy()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    print(\"\\n\"+\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "    ### For classification:\n",
    "    if regression_flag == 0:\n",
    "\n",
    "        ### Train model\n",
    "        train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "            train_model_classification(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name=name)\n",
    "\n",
    "        ### Evaluate model\n",
    "        test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "                valid_AUPR, valid_pred, valid_labels = \\\n",
    "                    eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx, name=name)\n",
    "\n",
    "        ### Save metrics and node predictions\n",
    "        train_metrics = [train_gene_ID, train_pred, train_labels, train_AUROC_vec, train_AUPR, train_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), train_metrics)\n",
    "\n",
    "        valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_AUROC_vec, valid_AUPR, valid_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), valid_metrics)\n",
    "\n",
    "        test_metrics = [test_gene_ID, test_pred, test_labels, test_AUROC, test_AUPR, ['na']]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), test_metrics)\n",
    "\n",
    "        dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "        df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label','Classification'])\n",
    "\n",
    "        for d in np.arange(len(dataset_list)):\n",
    "            dataset_metrics = dataset_list[d]\n",
    "            partial_metrics = pd.DataFrame()\n",
    "\n",
    "            partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "            partial_metrics['True Label'] = dataset_metrics[2]\n",
    "            partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "            partial_metrics['Classification'] = dataset_metrics[1]*1 + dataset_metrics[2]*2\n",
    "            partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=1, value='FP', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=2, value='FN', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=3, value='TP', inplace=True)\n",
    "\n",
    "            if d == 0:\n",
    "                partial_metrics['Dataset'] = 'Training'\n",
    "            elif d == 1:\n",
    "                partial_metrics['Dataset'] = 'Validation'\n",
    "            elif d == 2:\n",
    "                partial_metrics['Dataset'] = 'Testing'\n",
    "\n",
    "            df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "\n",
    "        df_gene_names = df_genes.iloc[:,:3]\n",
    "        df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                      \"hic_node_id\" : 'Node ID'})\n",
    "        df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "        df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,5,6,2,3,4]]]\n",
    "\n",
    "    ### For regression:\n",
    "    elif regression_flag == 1:\n",
    "\n",
    "        ### Train model\n",
    "        train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "            train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name=name)\n",
    "\n",
    "        ### Evaluate model\n",
    "        test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "                valid_pearson, valid_pred, valid_labels = \\\n",
    "                    eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx, name=name)\n",
    "\n",
    "        ### Save metrics and node predictions\n",
    "        train_metrics = [train_gene_ID, train_pred, train_labels, train_pearson_vec, train_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), train_metrics)\n",
    "\n",
    "        valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_pearson_vec, valid_loss_vec]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), valid_metrics)\n",
    "\n",
    "        test_metrics = [test_gene_ID, test_pred, test_labels, test_pearson, ['na']]\n",
    "        # np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), test_metrics)\n",
    "\n",
    "        dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "        df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label'])\n",
    "\n",
    "        for d in np.arange(len(dataset_list)):\n",
    "            dataset_metrics = dataset_list[d]\n",
    "            partial_metrics = pd.DataFrame()\n",
    "\n",
    "            partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "            partial_metrics['True Label'] = dataset_metrics[2]\n",
    "            partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "\n",
    "            if d == 0:\n",
    "                partial_metrics['Dataset'] = 'Training'\n",
    "            elif d == 1:\n",
    "                partial_metrics['Dataset'] = 'Validation'\n",
    "            elif d == 2:\n",
    "                partial_metrics['Dataset'] = 'Testing'\n",
    "\n",
    "            df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "\n",
    "        df_gene_names = df_genes.iloc[:,:3]\n",
    "        df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                      \"hic_node_id\" : 'Node ID'})\n",
    "        df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "        df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,4,5,2,3]]]\n",
    "\n",
    "\n",
    "    ### Print elapsed time and performance\n",
    "    elapsed = (time.time() - start_time)\n",
    "    elapsed_h = int(elapsed//3600)\n",
    "    elapsed_m = int((elapsed - elapsed_h*3600)//60)\n",
    "    elapsed_s = int(elapsed - elapsed_h*3600 - elapsed_m*60)\n",
    "    print('Elapsed time: {0:02d}:{1:02d}:{2:02d}'.format(elapsed_h, elapsed_m, elapsed_s))\n",
    "    \n",
    "    ### Save trained model parameters, model predictions CSV file, model performance/information\n",
    "    model_path = os.path.join(save_dir, 'model_' + date_and_time + '.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    df_full_metrics_filename = os.path.join(save_dir, 'model_predictions_GCN_' + date_and_time + '.csv')\n",
    "    df_full_metrics.to_csv(df_full_metrics_filename, index=False)\n",
    "\n",
    "    model_info_filename = os.path.join(save_dir,'model_' + date_and_time + '_info.txt')\n",
    "    f = open(model_info_filename, 'w')\n",
    "#     f.write('File name: ' + os.path.basename(__file__) + '\\n')\n",
    "    f.write('Model reference date and time: ' + date_and_time + '\\n\\n')\n",
    "    f.write('Start date: ' + mdy + '\\n')\n",
    "    f.write('Start time: ' + hm_colon + '\\n')\n",
    "    f.write('Total time: {0:02d}:{1:02d}:{2:02d}'.format(elapsed_h, elapsed_m, elapsed_s))\n",
    "    f.write('\\n\\n')\n",
    "    f.write('Task: ' + task + '\\n')\n",
    "    f.write('Cell line: ' + cell_line + '\\n')\n",
    "    f.write('Dataset split:\\n')\n",
    "    f.write('Training set: 70%' + '\\n')\n",
    "    f.write('Validation set: 15%' + '\\n')\n",
    "    f.write('Testing set: 15%' + '\\n\\n')\n",
    "    f.write('Performance:\\n')\n",
    "    if regression_flag == 0:\n",
    "        f.write('Test AUROC: ' + str(test_AUROC) + '\\n')\n",
    "        f.write('Test AUPR: ' + str(test_AUPR) + '\\n\\n')\n",
    "    elif regression_flag == 1:\n",
    "        f.write('Test PCC: ' + str(test_pearson) + '\\n\\n')\n",
    "    f.write('Hyperparameters:\\n')\n",
    "    f.write('Number of epochs: ' + str(max_epoch) + '\\n')\n",
    "    f.write('Learning rate :' + str(learning_rate) + '\\n')\n",
    "    f.write('Number of graph convolutional layers: ' + str(num_graph_conv_layers) + '\\n')\n",
    "    f.write('Graph convolutional layer size: ' + str(graph_conv_embed_size) + '\\n')\n",
    "    f.write('Number of linear layers: ' + str(num_lin_layers) + '\\n')\n",
    "    f.write('Linear hidden layer size: ' + str(lin_hidden_size) + '\\n\\n')\n",
    "    f.write('Model\\'s state_dict:\\n')\n",
    "\n",
    "    for param_tensor in model.state_dict():\n",
    "        f.write(str(param_tensor) + \"\\t\" + str(model.state_dict()[param_tensor].size()) + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "    print('\\nPerformance:')\n",
    "    if regression_flag == 0:\n",
    "        \n",
    "        print('Test AUROC:', test_AUROC, '\\n')\n",
    "        print('Test AUPR:', test_AUPR, '\\n\\n')\n",
    "        return (test_AUROC, test_AUPR)\n",
    "    \n",
    "    elif regression_flag == 1:\n",
    "        print('Test pearson:', test_pearson, '\\n')\n",
    "        return test_pearson\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30edcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores AUROC, AUPR, and PCC across all models for each cell line\n",
    "data_dict = {}\n",
    "data_dict['E116'] = []\n",
    "data_dict['E122'] = []\n",
    "data_dict['E123'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b91ba7",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b23c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2efc9e8e30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed587a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model date and time:\n",
      "2024-11-05-at-00-02-30 \n",
      "\n",
      "\n",
      "Cell line: E116\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([2, 100])\n",
      "fc3.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:00:16\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.9015144244304193 \n",
      "\n",
      "Test AUPR: 0.8824920173893717 \n",
      "\n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-02-47 \n",
      "\n",
      "\n",
      "Cell line: E116\n",
      "Task: Regression\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([1, 100])\n",
      "fc3.bias \t torch.Size([1])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2505])) that is different to the input size (torch.Size([2505, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:213: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:02:36\n",
      "\n",
      "Performance:\n",
      "Test pearson: 0.7595196277926578 \n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-05-23 \n",
      "\n",
      "\n",
      "Cell line: E122\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([2, 100])\n",
      "fc3.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:00:14\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.9025767499528315 \n",
      "\n",
      "Test AUPR: 0.8582701070695865 \n",
      "\n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-05-38 \n",
      "\n",
      "\n",
      "Cell line: E122\n",
      "Task: Regression\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([1, 100])\n",
      "fc3.bias \t torch.Size([1])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2502])) that is different to the input size (torch.Size([2502, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:213: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:02:38\n",
      "\n",
      "Performance:\n",
      "Test pearson: 0.7458674735971935 \n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-08-16 \n",
      "\n",
      "\n",
      "Cell line: E123\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([2, 100])\n",
      "fc3.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:00:14\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.9244208916083915 \n",
      "\n",
      "Test AUPR: 0.8996247328837349 \n",
      "\n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-08-31 \n",
      "\n",
      "\n",
      "Cell line: E123\n",
      "Task: Regression\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([1, 100])\n",
      "fc3.bias \t torch.Size([1])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2503])) that is different to the input size (torch.Size([2503, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Elapsed time: 00:02:38\n",
      "\n",
      "Performance:\n",
      "Test pearson: 0.7896886606162409 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:213: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "regression_flag = 0\n",
    "max_epoch = 1000\n",
    "learning_rate = 0.001\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 100\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "for line in data_dict:\n",
    "    cell_line = line\n",
    "    \n",
    "    regression_flag=0\n",
    "    num_classes = 2\n",
    "    task ='Classification'\n",
    "    \n",
    "    model = MLP_Classification(input_size=num_feat, hidden_sizes=[lin_hidden_size, lin_hidden_size], num_classes=num_classes)\n",
    "    \n",
    "    # MLP Classification Task\n",
    "    MLP_AUROC, MLP_AUPR = experiment(cell_line=cell_line, regression_flag=0, learning_rate=learning_rate, model=model, name='MLP')\n",
    "    \n",
    "    regression_flag = 1\n",
    "    num_classes = 1\n",
    "    task ='Regression'\n",
    "    \n",
    "    model = MLP_Regression(input_size=num_feat, hidden_sizes=[lin_hidden_size, lin_hidden_size])\n",
    "    \n",
    "    # MLP Regression Task\n",
    "    MLP_Pearson = experiment(cell_line=cell_line, regression_flag=1, learning_rate=learning_rate, model=model, name='MLP')\n",
    "    data_dict[line].append([MLP_AUROC, MLP_AUPR, MLP_Pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425bfeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E116': [[0.9015144244304193, 0.8824920173893717, 0.7595196277926578]],\n",
       " 'E122': [[0.9025767499528315, 0.8582701070695865, 0.7458674735971935]],\n",
       " 'E123': [[0.9244208916083915, 0.8996247328837349, 0.7896886606162409]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd5688",
   "metadata": {},
   "source": [
    "## GC-Merge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9700d316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2efc9e8e30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0b57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "regression_flag = 0\n",
    "max_epoch = 1000\n",
    "learning_rate = 0.001\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 100\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f44a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model date and time:\n",
      "2024-11-05-at-00-11-09 \n",
      "\n",
      "\n",
      "Cell line: E116\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.lin_l.weight \t torch.Size([256, 12])\n",
      "conv1.lin_l.bias \t torch.Size([256])\n",
      "conv2.lin_l.weight \t torch.Size([100, 512])\n",
      "conv2.lin_l.bias \t torch.Size([100])\n",
      "lin1.weight \t torch.Size([100, 100])\n",
      "lin1.bias \t torch.Size([100])\n",
      "lin2.weight \t torch.Size([2, 100])\n",
      "lin2.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:01:16\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.9114059849940267 \n",
      "\n",
      "Test AUPR: 0.8916850696103243 \n",
      "\n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-12-26 \n",
      "\n",
      "\n",
      "Cell line: E116\n",
      "Task: Regression\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.lin_l.weight \t torch.Size([256, 12])\n",
      "conv1.lin_l.bias \t torch.Size([256])\n",
      "conv2.lin_l.weight \t torch.Size([100, 512])\n",
      "conv2.lin_l.bias \t torch.Size([100])\n",
      "lin1.weight \t torch.Size([100, 100])\n",
      "lin1.bias \t torch.Size([100])\n",
      "lin2.weight \t torch.Size([1, 100])\n",
      "lin2.bias \t torch.Size([1])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:213: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:03:31\n",
      "\n",
      "Performance:\n",
      "Test pearson: 0.7773778360391718 \n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-15-58 \n",
      "\n",
      "\n",
      "Cell line: E122\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.lin_l.weight \t torch.Size([256, 12])\n",
      "conv1.lin_l.bias \t torch.Size([256])\n",
      "conv2.lin_l.weight \t torch.Size([100, 512])\n",
      "conv2.lin_l.bias \t torch.Size([100])\n",
      "lin1.weight \t torch.Size([100, 100])\n",
      "lin1.bias \t torch.Size([100])\n",
      "lin2.weight \t torch.Size([2, 100])\n",
      "lin2.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:01:11\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.8996972170059917 \n",
      "\n",
      "Test AUPR: 0.8658043644019671 \n",
      "\n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-17-09 \n",
      "\n",
      "\n",
      "Cell line: E122\n",
      "Task: Regression\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.lin_l.weight \t torch.Size([256, 12])\n",
      "conv1.lin_l.bias \t torch.Size([256])\n",
      "conv2.lin_l.weight \t torch.Size([100, 512])\n",
      "conv2.lin_l.bias \t torch.Size([100])\n",
      "lin1.weight \t torch.Size([100, 100])\n",
      "lin1.bias \t torch.Size([100])\n",
      "lin2.weight \t torch.Size([1, 100])\n",
      "lin2.bias \t torch.Size([1])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:213: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:03:32\n",
      "\n",
      "Performance:\n",
      "Test pearson: 0.7501198589861636 \n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-20-41 \n",
      "\n",
      "\n",
      "Cell line: E123\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.lin_l.weight \t torch.Size([256, 12])\n",
      "conv1.lin_l.bias \t torch.Size([256])\n",
      "conv2.lin_l.weight \t torch.Size([100, 512])\n",
      "conv2.lin_l.bias \t torch.Size([100])\n",
      "lin1.weight \t torch.Size([100, 100])\n",
      "lin1.bias \t torch.Size([100])\n",
      "lin2.weight \t torch.Size([2, 100])\n",
      "lin2.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_3023/3927644200.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:01:12\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.9214212442939939 \n",
      "\n",
      "Test AUPR: 0.8816959579287794 \n",
      "\n",
      "\n",
      "Model date and time:\n",
      "2024-11-05-at-00-21-53 \n",
      "\n",
      "\n",
      "Cell line: E123\n",
      "Task: Regression\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "conv1.lin_l.weight \t torch.Size([256, 12])\n",
      "conv1.lin_l.bias \t torch.Size([256])\n",
      "conv2.lin_l.weight \t torch.Size([100, 512])\n",
      "conv2.lin_l.bias \t torch.Size([100])\n",
      "lin1.weight \t torch.Size([100, 100])\n",
      "lin1.bias \t torch.Size([100])\n",
      "lin2.weight \t torch.Size([1, 100])\n",
      "lin2.bias \t torch.Size([1])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Elapsed time: 00:03:33\n",
      "\n",
      "Performance:\n",
      "Test pearson: 0.7958508999074185 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023/3927644200.py:213: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for line in data_dict:\n",
    "    cell_line = line\n",
    "    \n",
    "    regression_flag=0\n",
    "    num_classes = 2\n",
    "    task='Classification'\n",
    "    graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "    lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, num_classes)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "    \n",
    "    model = GCN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "    \n",
    "    # GCN Classification Task\n",
    "    GCN_AUROC, GCN_AUPR = experiment(cell_line=cell_line, regression_flag=regression_flag, learning_rate=learning_rate, model=model)\n",
    "    \n",
    "    regression_flag = 1\n",
    "    num_classes = 1\n",
    "    task = 'Regression'\n",
    "    \n",
    "    graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "    lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, num_classes)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "    \n",
    "    model = GCN_regression(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "    \n",
    "    # GCN Regression Task\n",
    "    GCN_Pearson = experiment(cell_line=cell_line, regression_flag=regression_flag, learning_rate=learning_rate, model=model)\n",
    "    \n",
    "    data_dict[line].append([GCN_AUROC, GCN_AUPR, GCN_Pearson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0db670c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E116': [[0.9015144244304193, 0.8824920173893717, 0.7595196277926578],\n",
       "  [0.9114059849940267, 0.8916850696103243, 0.7773778360391718]],\n",
       " 'E122': [[0.9025767499528315, 0.8582701070695865, 0.7458674735971935],\n",
       "  [0.8996972170059917, 0.8658043644019671, 0.7501198589861636]],\n",
       " 'E123': [[0.9244208916083915, 0.8996247328837349, 0.7896886606162409],\n",
       "  [0.9214212442939939, 0.8816959579287794, 0.7958508999074185]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3f9fe",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2df38e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2efc9e8e30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11e5aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "cell_line = ...\n",
    "regression_flag = ...\n",
    "max_epoch = ...\n",
    "learning_rate = ...\n",
    "num_graph_conv_layers = ...\n",
    "graph_conv_embed_size = ...\n",
    "num_lin_layers = ...\n",
    "lin_hidden_size = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b97b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression_flag == 0:\n",
    "    num_classes = 2\n",
    "    task = 'Classification'\n",
    "else:\n",
    "    num_classes = 1\n",
    "    task = 'Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42a22d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3238120964.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    input_data = Your data\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "INPUT_LENGTH = 6   # Length of each input sequence\n",
    "NUM_CLASSES = 2    # Binary classification\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "input_data = Your data\n",
    "\n",
    "target_labels = torch.randint(0, 2, (NUM_SAMPLES,))\n",
    "\n",
    "output = model(input_data)\n",
    "loss = criterion(output, target_labels)\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "dataset = TensorDataset(input_data, target_labels)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_inputs, batch_labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch_inputs)\n",
    "        loss = criterion(output, batch_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89142988",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e918e9c-c077-49a8-ace9-c1850083b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract the cell lines and their corresponding data\n",
    "cell_lines = list(data_dict.keys())\n",
    "categories = cell_lines\n",
    "values = [[v[0] for v in data_dict[cell_lines[0]]], [v[0] for v in data_dict[cell_lines[1]]], [v[0] for v in data_dict[cell_lines[2]]]]\n",
    "values\n",
    "\n",
    "AUROC_MLP = [data_dict[line][0][0] for line in cell_lines]\n",
    "PCC_MLP = [data_dict[line][0][2] for line in cell_lines]\n",
    "\n",
    "AUROC_GCN = [data_dict[line][1][0] for line in cell_lines]\n",
    "PCC_GCN = [data_dict[line][1][2] for line in cell_lines]\n",
    "\n",
    "# AUROC graphs\n",
    "X_axis = np.arange(0,len(categories))\n",
    "plt.bar(X_axis + 0.2, AUROC_MLP, 0.4, label='MLP')\n",
    "plt.bar(X_axis-0.2, AUROC_GCN, 0.4, label='GCN')\n",
    "plt.xticks(X_axis, categories)\n",
    "plt.xlabel(\"Cell lines\")\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# PCC Graphs\n",
    "plt.bar(X_axis + 0.2, PCC_MLP, 0.4, label='MLP')\n",
    "plt.bar(X_axis-0.2, PCC_GCN, 0.4, label='GCN')\n",
    "plt.xticks(X_axis, categories)\n",
    "plt.xlabel(\"Cell lines\")\n",
    "plt.ylabel(\"PCC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121179d2-6202-4fa3-ba15-fec13602bee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
