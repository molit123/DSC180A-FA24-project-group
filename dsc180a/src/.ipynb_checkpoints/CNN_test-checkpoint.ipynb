{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b1e9a1-1f6f-46e2-ba57-f305b4d5117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model_classes_ import GCN_classification, GCN_regression, MLP_Classification, MLP_Regression#, SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cca429-33d4-4451-8daf-01b70738caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())  \u001b[38;5;66;03m# Should print `True`\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())  \u001b[38;5;66;03m# Should print the number of GPUs available\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Should print the current GPU ID (e.g., `0`)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# Should print the GPU name\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:787\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    786\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should print `True`\n",
    "print(torch.cuda.device_count())  # Should print the number of GPUs available\n",
    "print(torch.cuda.current_device())  # Should print the current GPU ID (e.g., `0`)\n",
    "print(torch.cuda.get_device_name(0))  # Should print the GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598df98-87eb-460a-a712-66e849dc4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "code break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02936d67-800f-4c18-b355-908b60a35865",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fced5-e6cd-43f4-97a6-4f50d5456aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)\n",
    "regression_flag = 0\n",
    "max_epoch = 50\n",
    "learning_rate = 0.001\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 100\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_runs = 10\n",
    "graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "lin_hidden_sizes_r = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, 1)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [1]\n",
    "lin_hidden_sizes_c = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, 2)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1a997-6bf2-4c2c-bbb9-333b82b81dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimentCNN(model, cell_line, regression_flag, optimizer, criterion, num_epochs=10):\n",
    "    # Create all paths\n",
    "    base_path = os.getcwd()\n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    \n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "    hms = allNodes_hms[:, 1:] # only includes features, not node ids\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) # shape: [279606, 6]\n",
    "    allNodes = allNodes_hms[:, 0].astype(int) # shape: [279606,1]\n",
    "    \n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int) # shape: [16699,1]\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "    \n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    # Generate y labels\n",
    "    geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "    allLabs[geneNodes] = geneLabs\n",
    "    Y = torch.tensor(allLabs).long() # shape: [279606,1]\n",
    "\n",
    "    # Shuffle indices\n",
    "    pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "    \n",
    "    fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "    fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "    train_idx = pred_idx_shuff[:fin_train]\n",
    "    val_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "    test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "    # Generate train, validation, and test sets\n",
    "    train_data = X[targetNode_mask][train_idx]\n",
    "    val_data = X[targetNode_mask][val_idx]\n",
    "    test_data = X[targetNode_mask][test_idx]\n",
    "    \n",
    "\n",
    "    if not regression_flag:\n",
    "        train_labels = torch.tensor(geneNodes_labs[train_idx][:,1]).long()\n",
    "        val_labels = torch.tensor(geneNodes_labs[val_idx][:,1]).long()\n",
    "        test_labels = torch.tensor(geneNodes_labs[test_idx][:,1]).long()\n",
    "    else:\n",
    "        train_labels = torch.tensor(geneNodes_labs[train_idx][:,1]).float()\n",
    "        val_labels = torch.tensor(geneNodes_labs[val_idx][:,1]).float()\n",
    "        test_labels = torch.tensor(geneNodes_labs[test_idx][:,1]).float()\n",
    "        \n",
    "\n",
    "    # Reformat data\n",
    "    train_data = train_data.unsqueeze(1)\n",
    "    val_data = val_data.unsqueeze(1)\n",
    "    test_data = test_data.unsqueeze(1)\n",
    "\n",
    "    # Create data loaders\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    print(\"Create data loaders\")\n",
    "    train_dataset = TensorDataset(train_data, train_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    val_dataset = TensorDataset(val_data, val_labels)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    test_dataset = TensorDataset(test_data, test_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    print(\"Data loaders created\")\n",
    "    print(f\"Train loader shape: {len(train_loader)}\")\n",
    "    print(f\"Val loader shape: {len(val_loader)}\")\n",
    "    print(f\"Test loader shape: {len(test_loader)}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # Train data\n",
    "    print(\"Begin training + evaluation.../n/n\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        epoch_loss = 0\n",
    "        for batch_inputs, batch_labels in train_loader:\n",
    "            batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(batch_inputs)\n",
    "            if regression_flag:\n",
    "                batch_labels = batch_labels.view(-1, 1)\n",
    "                \n",
    "            loss = criterion(output, batch_labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        end = time.time()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Training time: {end-start} seconds\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        test_outputs = []\n",
    "        test_targets = []\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_labels in test_loader:\n",
    "                output = model(batch_inputs).squeeze()\n",
    "                test_outputs.append(output)\n",
    "                test_targets.append(batch_labels)\n",
    "        \n",
    "        test_outputs = torch.cat(test_outputs).numpy()\n",
    "        test_targets = torch.cat(test_targets).numpy()\n",
    "        \n",
    "        end = time.time()\n",
    "        print(f\"Testing time: {end-start} seconds\")\n",
    "        if not regression_flag:\n",
    "            auroc = roc_auc_score(test_targets, test_outputs)\n",
    "            print(f\"Epoch {epoch + 1}, AUROC Score: {auroc:.4f}\")\n",
    "            metric_scores.append(auroc)\n",
    "        else:\n",
    "            # Calculate PCC for regression\n",
    "            pcc, _ = pearsonr(test_targets, test_outputs)\n",
    "            print(f\"Epoch {epoch + 1}, PCC Score: {pcc:.4f}\")\n",
    "            metric_scores.append(pcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac58f02-9f63-4448-ad0a-e81caec8c920",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809eb65-49d2-4b90-a5bb-f5febee8b101",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea0681-d9a0-4299-aac3-81fd68b3d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, regression_flag=0):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        INPUT_LENGTH = 6\n",
    "        NUM_CLASSES = 2 if not regression_flag else 1\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * INPUT_LENGTH, 32)\n",
    "        self.fc2 = nn.Linear(32, NUM_CLASSES)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "            x = self.relu(self.conv1(x))\n",
    "            x = x.view(x.size(0), -1)         \n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.fc2(x)  \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5cc7ba-5f0f-407d-8331-aa1dc396b0b3",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eba32a-1653-417c-b1a7-3475a443232e",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea550095-9793-4a21-9221-0ac29ae74929",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d495e2-8494-4a96-908b-41467061ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(regression_flag=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "cell_line = 'E116'\n",
    "regression_flag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985c3f3-e284-49ad-9c17-b325a57df6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentCNN(model, cell_line, regression_flag, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019cf1e-7cca-4f41-ba93-68a9585f8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(regression_flag=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cell_line = 'E116'\n",
    "regression_flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78e6f9-3221-4bd4-9d9b-906c861d5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentCNN(model, cell_line, regression_flag, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967a9ad-ad62-4df4-92b7-5712bb61de33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7d024-66ed-4501-8a7d-d8ef5e135660",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d40d79b-ac70-4fff-9088-34b163104b41",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
