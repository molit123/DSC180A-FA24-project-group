{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bd3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from model_classes_ import GCN_classification, GCN_regression, MLP_Classification, MLP_Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316b5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name='GCN'):\n",
    "    '''\n",
    "    Trains model for classification task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch\n",
    "    train_AUROC_vec [array]: Training AUROC score for each epoch\n",
    "    valid_loss_vec [array]: Validation loss for each epoch\n",
    "    valid_AUROC_vec [array]: Validation AUROC score for each epoch\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx]\n",
    "        elif name == 'MLP':\n",
    "            forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "            train_scores = forward_scores[train_idx].squeeze()        \n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores) \n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = to_cpu_npy(train_softmax)\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = to_cpu_npy(valid_softmax)\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:,1], average=\"micro\")\n",
    "        \n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec\n",
    "\n",
    "\n",
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx, name='GCN'):\n",
    "    '''\n",
    "    Runs fully trained classification model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_AUROC [float]: Test set AUROC score;\n",
    "        analogous for train_AUROC (training set) and valid_AUPR (validation set)\n",
    "    test_AUPR [float]: Test set AUPR score\n",
    "        analogous for train_AUPR (training set) and valid_AUPR (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels;\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    if name == 'GCN':\n",
    "            forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "    elif name == 'MLP':\n",
    "        forward_scores = model(graph.x.float())[targetNode_mask]\n",
    "    \n",
    "    test_scores = forward_scores[test_idx]\n",
    "    \n",
    "    test_softmax, test_pred = model.calc_softmax_pred(test_scores) \n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_pred = to_cpu_npy(test_pred)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_precision, test_recall, thresholds = precision_recall_curve(test_labels, test_softmax[:,1])\n",
    "    test_AUPR = auc(test_recall, test_precision)\n",
    "    # test_F1 = f1_score(test_labels, test_pred, average=\"micro\")\n",
    "    \n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_softmax, train_pred = model.calc_softmax_pred(train_scores) \n",
    "    train_pred = to_cpu_npy(train_pred)\n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_precision, train_recall, thresholds = precision_recall_curve(train_labels, train_softmax[:,1])\n",
    "    train_AUPR = auc(train_recall, train_precision)\n",
    "    # train_F1 = f1_score(train_labels, train_pred, average=\"micro\")\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_softmax, valid_pred = model.calc_softmax_pred(valid_scores) \n",
    "    valid_pred = to_cpu_npy(valid_pred)\n",
    "    valid_softmax = to_cpu_npy(valid_softmax)\n",
    "    valid_precision, valid_recall, thresholds = precision_recall_curve(valid_labels, valid_softmax[:,1])\n",
    "    valid_AUPR = auc(valid_recall, valid_precision)\n",
    "    # valid_F1 = f1_score(valid_labels, valid_pred, average=\"micro\")\n",
    "\n",
    "    return test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels\n",
    "\n",
    "\n",
    "def train_model_regression(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    '''\n",
    "    Trains model for regression task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch;\n",
    "        analagous for valid_loss_vec (validation set)\n",
    "    train_pearson_vec [array]: Training PCC for each epoch;\n",
    "        analogous for valid_pearson_vec (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_pearson_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "        \n",
    "        train_scores = forward_scores[train_idx]\n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.FloatTensor(train_labels).to(device))\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        train_scores = to_cpu_npy(train_scores)\n",
    "        train_pearson = calc_pearson(train_scores, train_labels)\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.FloatTensor(valid_labels).to(device))\n",
    "        valid_scores = to_cpu_npy(valid_scores)\n",
    "        valid_pearson  = calc_pearson(valid_scores, valid_labels)\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        \n",
    "        train_pearson_vec[e] = train_pearson\n",
    "        valid_pearson_vec[e] = valid_pearson\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec\n",
    "\n",
    "\n",
    "def eval_model_regression(model, graph, targetNode_mask, train_idx, valid_idx, test_idx):\n",
    "    '''\n",
    "    Runs fully trained regression model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_pearson [float]: PCC for test set;\n",
    "        analogous for train_pearson (training set) and valid_pearson (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels (expression values);\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_pred = to_cpu_npy(test_scores)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    test_pearson = calc_pearson(test_pred, test_labels)\n",
    "\n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_pred = to_cpu_npy(train_scores)\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_pearson = calc_pearson(train_pred, train_labels)\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_pred = to_cpu_npy(valid_scores)\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_pearson = calc_pearson(valid_pred, valid_labels)\n",
    "\n",
    "    return test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "        valid_pearson, valid_pred, valid_labels\n",
    "        \n",
    "\n",
    "def calc_pearson(scores, targets):\n",
    "    '''\n",
    "    Calculates Pearson correlation coefficient (PCC) between predicted \\\n",
    "        expression levels and true expression levels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores [array]: Predicted expression levels\n",
    "    targets [array]: True expression levels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pcc [float]: Pearson correlation coefficient\n",
    "\n",
    "    '''\n",
    "    pcc, _ = pearsonr(scores, targets)\n",
    "            \n",
    "    return pcc\n",
    "    \n",
    "    \n",
    "def to_cpu_npy(x):\n",
    "    '''\n",
    "    Simple helper function to transfer GPU tensors to CPU numpy matrices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x [tensor]: PyTorch tensor stored on GPU\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_x [array]: Numpy array stored on CPU\n",
    "\n",
    "    '''\n",
    "\n",
    "    new_x = x.cpu().detach().numpy()\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaffd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_res = 10000\n",
    "hic_res = 10000\n",
    "num_hm = 6\n",
    "num_feat = int((hic_res/chip_res)*num_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652237a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains and evaluates models\n",
    "###Test for GPU availability\n",
    "cuda_flag = torch.cuda.is_available()\n",
    "if cuda_flag:  \n",
    "  dev = \"cuda\" \n",
    "else:\n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adbc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(cell_line, regression_flag, model, max_epoch=1000, learning_rate=0.001, name='GCN'):\n",
    "    \"\"\"\n",
    "    \n",
    "        Trains and evaluates models.\n",
    "        \n",
    "        Parameters:\n",
    "        cell_line: cell line to be trained on\n",
    "        regression_flag: 0 (Classification) or 1 (Regression)\n",
    "        model: GCN, MLP, or CNN model\n",
    "        name: GCN, MLP, CNN\n",
    "        \n",
    "        Returns:\n",
    "        Performance scores based on type of task\n",
    "        \n",
    "    \"\"\"\n",
    "    if regression_flag == 0:\n",
    "        num_classes = 2\n",
    "        task = 'Classification'\n",
    "    else:\n",
    "        num_classes = 1\n",
    "        task = 'Regression'\n",
    "\n",
    "    # random_seed = random.randint(0,10000)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "    ###Initialize start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    today = date.today()\n",
    "    mdy = today.strftime(\"%Y-%m-%d\")\n",
    "    clock = datetime.now()\n",
    "    hms = clock.strftime(\"%H-%M-%S\")\n",
    "    hm = clock.strftime(\"%Hh-%Mm\")\n",
    "    hm_colon = clock.strftime(\"%H:%M\")\n",
    "    date_and_time = mdy + '-at-' + hms\n",
    "    \n",
    "    ###Load input files\n",
    "    base_path = os.getcwd()\n",
    "    save_dir = os.path.join(base_path, 'data', cell_line, 'saved_runs')\n",
    "    hic_sparse_mat_file = os.path.join(base_path, 'data', cell_line, 'hic_sparse.npz')\n",
    "    np_nodes_lab_genes_file = os.path.join(base_path, 'data',  cell_line, \\\n",
    "        'np_nodes_lab_genes_reg' + str(regression_flag) + '.npy')\n",
    "    np_hmods_norm_all_file = os.path.join(base_path, 'data', cell_line, \\\n",
    "        'np_hmods_norm_chip_' + str(chip_res) + 'bp.npy')\n",
    "    df_genes_file = os.path.join(base_path, 'data', cell_line, 'df_genes_reg' + str(regression_flag) + '.pkl')\n",
    "    df_genes = pd.read_pickle(df_genes_file)\n",
    "    \n",
    "    # Provide hyperparameters\n",
    "#     print(os.path.basename(__file__))\n",
    "    print('Model date and time:')\n",
    "    print(date_and_time, '\\n\\n')\n",
    "    print('Cell line:', cell_line)\n",
    "    print('Task:', task)\n",
    "    print('ChIP-seq resolution:', str(chip_res))\n",
    "    print('\\n')\n",
    "    print('Training set: 70%')\n",
    "    print('Validation set: 15%')\n",
    "    print('Testing set: 15%')\n",
    "    print('\\n')\n",
    "    print('Model hyperparameters: ')\n",
    "    print('Number of epochs:', max_epoch)\n",
    "    print('Learning rate:', learning_rate)\n",
    "    \n",
    "    # Load data\n",
    "    mat = load_npz(hic_sparse_mat_file)\n",
    "    allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "    hms = allNodes_hms[:, 1:] #only includes features, not node ids\n",
    "    X = torch.tensor(hms).float().reshape(-1, num_feat) \n",
    "    allNodes = allNodes_hms[:, 0].astype(int)\n",
    "    geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "    geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "    allLabs = -1*np.ones(np.shape(allNodes))\n",
    "\n",
    "    targetNode_mask = torch.tensor(geneNodes).long()\n",
    "\n",
    "    if regression_flag == 0:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(int)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).long()\n",
    "    else:\n",
    "        geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "        allLabs[geneNodes] = geneLabs\n",
    "        Y = torch.tensor(allLabs).float()\n",
    "\n",
    "    extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "    data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "    G = data\n",
    "    \n",
    "    # Define convolutional and linear layer input/output sizes\n",
    "    graph_conv_layer_sizes = [num_feat] + \\\n",
    "        [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "              for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "\n",
    "    lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "        [int(max(lin_hidden_size, num_classes)) \\\n",
    "              for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "    \n",
    "    # Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "    pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "    fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "    fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "    train_idx = pred_idx_shuff[:fin_train]\n",
    "    valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "    test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "    train_gene_ID = targetNode_mask[train_idx].numpy()\n",
    "    valid_gene_ID = targetNode_mask[valid_idx].numpy()\n",
    "    test_gene_ID = targetNode_mask[test_idx].numpy()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    print(\"\\n\"+\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "    ### For classification:\n",
    "    if regression_flag == 0:\n",
    "\n",
    "        ### Train model\n",
    "        train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "            train_model_classification(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer, name=name)\n",
    "\n",
    "        ### Evaluate model\n",
    "        test_AUROC, test_AUPR, test_pred, test_labels, train_AUPR, train_pred, train_labels, \\\n",
    "                valid_AUPR, valid_pred, valid_labels = \\\n",
    "                    eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx, name=name)\n",
    "\n",
    "        ### Save metrics and node predictions\n",
    "        train_metrics = [train_gene_ID, train_pred, train_labels, train_AUROC_vec, train_AUPR, train_loss_vec]\n",
    "        np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), train_metrics)\n",
    "\n",
    "        valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_AUROC_vec, valid_AUPR, valid_loss_vec]\n",
    "        np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), valid_metrics)\n",
    "\n",
    "        test_metrics = [test_gene_ID, test_pred, test_labels, test_AUROC, test_AUPR, ['na']]\n",
    "        np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), test_metrics)\n",
    "\n",
    "        dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "        df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label','Classification'])\n",
    "\n",
    "        for d in np.arange(len(dataset_list)):\n",
    "            dataset_metrics = dataset_list[d]\n",
    "            partial_metrics = pd.DataFrame()\n",
    "\n",
    "            partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "            partial_metrics['True Label'] = dataset_metrics[2]\n",
    "            partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "            partial_metrics['Classification'] = dataset_metrics[1]*1 + dataset_metrics[2]*2\n",
    "            partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=1, value='FP', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=2, value='FN', inplace=True)\n",
    "            partial_metrics['Classification'].replace(to_replace=3, value='TP', inplace=True)\n",
    "\n",
    "            if d == 0:\n",
    "                partial_metrics['Dataset'] = 'Training'\n",
    "            elif d == 1:\n",
    "                partial_metrics['Dataset'] = 'Validation'\n",
    "            elif d == 2:\n",
    "                partial_metrics['Dataset'] = 'Testing'\n",
    "\n",
    "            df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "\n",
    "        df_gene_names = df_genes.iloc[:,:3]\n",
    "        df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                      \"hic_node_id\" : 'Node ID'})\n",
    "        df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "        df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,5,6,2,3,4]]]\n",
    "\n",
    "    ### For regression:\n",
    "    elif regression_flag == 1:\n",
    "\n",
    "        ### Train model\n",
    "        train_loss_vec, train_pearson_vec, valid_loss_vec, valid_pearson_vec = \\\n",
    "            train_model_regression(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "\n",
    "        ### Evaluate model\n",
    "        test_pearson, test_pred, test_labels, train_pearson, train_pred, train_labels, \\\n",
    "                valid_pearson, valid_pred, valid_labels = \\\n",
    "                    eval_model_regression(model, G, targetNode_mask, train_idx, valid_idx, test_idx)\n",
    "\n",
    "        ### Save metrics and node predictions\n",
    "        train_metrics = [train_gene_ID, train_pred, train_labels, train_pearson_vec, train_loss_vec]\n",
    "        np.save(os.path.join(save_dir, 'model_' + date_and_time + '_train_metrics'  + '.npy'), train_metrics)\n",
    "\n",
    "        valid_metrics = [valid_gene_ID, valid_pred, valid_labels, valid_pearson_vec, valid_loss_vec]\n",
    "        np.save(os.path.join(save_dir, 'model_' + date_and_time + '_valid_metrics'  + '.npy'), valid_metrics)\n",
    "\n",
    "        test_metrics = [test_gene_ID, test_pred, test_labels, test_pearson, ['na']]\n",
    "        np.save(os.path.join(save_dir, 'model_' + date_and_time + '_test_metrics'  + '.npy'), test_metrics)\n",
    "\n",
    "        dataset_list = [train_metrics, valid_metrics, test_metrics]\n",
    "        df_full_metrics = pd.DataFrame(columns=['Dataset','Node ID','True Label','Predicted Label'])\n",
    "\n",
    "        for d in np.arange(len(dataset_list)):\n",
    "            dataset_metrics = dataset_list[d]\n",
    "            partial_metrics = pd.DataFrame()\n",
    "\n",
    "            partial_metrics['Node ID'] = dataset_metrics[0]\n",
    "            partial_metrics['True Label'] = dataset_metrics[2]\n",
    "            partial_metrics['Predicted Label'] = dataset_metrics[1]\n",
    "\n",
    "            if d == 0:\n",
    "                partial_metrics['Dataset'] = 'Training'\n",
    "            elif d == 1:\n",
    "                partial_metrics['Dataset'] = 'Validation'\n",
    "            elif d == 2:\n",
    "                partial_metrics['Dataset'] = 'Testing'\n",
    "\n",
    "            df_full_metrics = pd.concat([df_full_metrics, partial_metrics], ignore_index=True)\n",
    "\n",
    "        df_gene_names = df_genes.iloc[:,:3]\n",
    "        df_gene_names = df_gene_names.rename(columns={\"gene_catalog_name\": \"ENSEMBL_ID\", \"abbrev\": \"Abbreviation\",\n",
    "                                      \"hic_node_id\" : 'Node ID'})\n",
    "        df_full_metrics = pd.merge(df_full_metrics, df_gene_names, how='inner', on='Node ID')\n",
    "        df_full_metrics = df_full_metrics[df_full_metrics.columns[[0,1,4,5,2,3]]]\n",
    "\n",
    "\n",
    "    ### Print elapsed time and performance\n",
    "    elapsed = (time.time() - start_time)\n",
    "    elapsed_h = int(elapsed//3600)\n",
    "    elapsed_m = int((elapsed - elapsed_h*3600)//60)\n",
    "    elapsed_s = int(elapsed - elapsed_h*3600 - elapsed_m*60)\n",
    "    print('Elapsed time: {0:02d}:{1:02d}:{2:02d}'.format(elapsed_h, elapsed_m, elapsed_s))\n",
    "    \n",
    "    ### Save trained model parameters, model predictions CSV file, model performance/information\n",
    "    model_path = os.path.join(save_dir, 'model_' + date_and_time + '.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    df_full_metrics_filename = os.path.join(save_dir, 'model_predictions_GCN_' + date_and_time + '.csv')\n",
    "    df_full_metrics.to_csv(df_full_metrics_filename, index=False)\n",
    "\n",
    "    model_info_filename = os.path.join(save_dir,'model_' + date_and_time + '_info.txt')\n",
    "    f = open(model_info_filename, 'w')\n",
    "#     f.write('File name: ' + os.path.basename(__file__) + '\\n')\n",
    "    f.write('Model reference date and time: ' + date_and_time + '\\n\\n')\n",
    "    f.write('Start date: ' + mdy + '\\n')\n",
    "    f.write('Start time: ' + hm_colon + '\\n')\n",
    "    f.write('Total time: {0:02d}:{1:02d}:{2:02d}'.format(elapsed_h, elapsed_m, elapsed_s))\n",
    "    f.write('\\n\\n')\n",
    "    f.write('Task: ' + task + '\\n')\n",
    "    f.write('Cell line: ' + cell_line + '\\n')\n",
    "    f.write('Dataset split:\\n')\n",
    "    f.write('Training set: 70%' + '\\n')\n",
    "    f.write('Validation set: 15%' + '\\n')\n",
    "    f.write('Testing set: 15%' + '\\n\\n')\n",
    "    f.write('Performance:\\n')\n",
    "    if regression_flag == 0:\n",
    "        f.write('Test AUROC: ' + str(test_AUROC) + '\\n')\n",
    "        f.write('Test AUPR: ' + str(test_AUPR) + '\\n\\n')\n",
    "    elif regression_flag == 1:\n",
    "        f.write('Test PCC: ' + str(test_pearson) + '\\n\\n')\n",
    "    f.write('Hyperparameters:\\n')\n",
    "    f.write('Number of epochs: ' + str(max_epoch) + '\\n')\n",
    "    f.write('Learning rate :' + str(learning_rate) + '\\n')\n",
    "    f.write('Number of graph convolutional layers: ' + str(num_graph_conv_layers) + '\\n')\n",
    "    f.write('Graph convolutional layer size: ' + str(graph_conv_embed_size) + '\\n')\n",
    "    f.write('Number of linear layers: ' + str(num_lin_layers) + '\\n')\n",
    "    f.write('Linear hidden layer size: ' + str(lin_hidden_size) + '\\n\\n')\n",
    "    f.write('Model\\'s state_dict:\\n')\n",
    "\n",
    "    for param_tensor in model.state_dict():\n",
    "        f.write(str(param_tensor) + \"\\t\" + str(model.state_dict()[param_tensor].size()) + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "    print('\\nPerformance:')\n",
    "    if regression_flag == 0:\n",
    "        \n",
    "        print('Test AUROC:', test_AUROC, '\\n')\n",
    "        print('Test AUPR:', test_AUPR, '\\n\\n')\n",
    "        return {'Test AUROC': test_AUROC, 'Test AUPR': test_AUPR}\n",
    "    \n",
    "    elif regression_flag == 1:\n",
    "        print('Test pearson:', test_pearson, '\\n')\n",
    "        return {'Test Pearson': test_pearson}\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b91ba7",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b94bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2378ad29d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed587a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "cell_line = \"E122\"\n",
    "regression_flag = 0\n",
    "max_epoch = 1000\n",
    "learning_rate = 0.001\n",
    "num_lin_layers = 2\n",
    "lin_hidden_size = 100\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40b4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression_flag == 0:\n",
    "    num_classes = 2\n",
    "    task = 'Classification'\n",
    "else:\n",
    "    num_classes = 1\n",
    "    task = 'Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "174373dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model date and time:\n",
      "2024-11-04-at-19-25-00 \n",
      "\n",
      "\n",
      "Cell line: E122\n",
      "Task: Classification\n",
      "ChIP-seq resolution: 10000\n",
      "\n",
      "\n",
      "Training set: 70%\n",
      "Validation set: 15%\n",
      "Testing set: 15%\n",
      "\n",
      "\n",
      "Model hyperparameters: \n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.001\n",
      "\n",
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 6])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([100, 100])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc3.weight \t torch.Size([2, 100])\n",
      "fc3.bias \t torch.Size([2])\n",
      "\n",
      "\n",
      "Epoch 0 out of 1000\n",
      "Epoch 100 out of 1000\n",
      "Epoch 200 out of 1000\n",
      "Epoch 300 out of 1000\n",
      "Epoch 400 out of 1000\n",
      "Epoch 500 out of 1000\n",
      "Epoch 600 out of 1000\n",
      "Epoch 700 out of 1000\n",
      "Epoch 800 out of 1000\n",
      "Epoch 900 out of 1000\n",
      "Elapsed time: 00:00:14\n",
      "\n",
      "Performance:\n",
      "Test AUROC: 0.8943185639522766 \n",
      "\n",
      "Test AUPR: 0.8695976177624237 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "/tmp/ipykernel_4500/3292065973.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_4500/3292065973.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n",
      "/tmp/ipykernel_4500/3292065973.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  partial_metrics['Classification'].replace(to_replace=0, value='TN', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test AUROC': 0.8943185639522766, 'Test AUPR': 0.8695976177624237}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_Classification(input_size=num_feat, hidden_sizes=[lin_hidden_size, lin_hidden_size], num_classes=num_classes)\n",
    "experiment(cell_line=cell_line, regression_flag=0, learning_rate=learning_rate, model=model, name='MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd5688",
   "metadata": {},
   "source": [
    "## GC-Merge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "cell_line = ...\n",
    "regression_flag = ...\n",
    "max_epoch = ...\n",
    "learning_rate = ...\n",
    "num_graph_conv_layers = ...\n",
    "graph_conv_embed_size = ...\n",
    "num_lin_layers = ...\n",
    "lin_hidden_size = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56315ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression_flag == 0:\n",
    "    num_classes = 2\n",
    "    task = 'Classification'\n",
    "else:\n",
    "    num_classes = 1\n",
    "    task = 'Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3f9fe",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "\n",
    "random_seed = random.randint(0,10000)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# Hyperparameters\n",
    "cell_line = ...\n",
    "regression_flag = ...\n",
    "max_epoch = ...\n",
    "learning_rate = ...\n",
    "num_graph_conv_layers = ...\n",
    "graph_conv_embed_size = ...\n",
    "num_lin_layers = ...\n",
    "lin_hidden_size = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression_flag == 0:\n",
    "    num_classes = 2\n",
    "    task = 'Classification'\n",
    "else:\n",
    "    num_classes = 1\n",
    "    task = 'Regression'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
